AWSTemplateFormatVersion: '2010-09-09'
Description: Organization data collections.
Parameters:
  ManagementRoleName:
    Type: String
    Description: The name of the IAM role that will be deployed in the management account which can retrieve AWS Organization data. KEEP THE SAME AS WHAT IS DEPLOYED INTO MANAGEMENT ACCOUNT
  ManagementAccountID:
    Type: String
    AllowedPattern: ([a-z0-9\-, ]*?$)
    Description: "(Ex: 123456789,098654321,789054312) List of Payer IDs you wish to collect data for. Can just be one Accounts"
  ResourcePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to be created to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  DataBucketsKmsKeysArns:
    Type: String
    Description: "ARNs of KMS Keys for data buckets and/or Glue Catalog. Comma separated list, no spaces. Keep empty if data Buckets and Glue Catalog are not Encrypted with KMS. You can also set it to '*' to grant decrypt permission for all the keys."
    Default: ""
Outputs:
  LambdaFunctionName:
    Value: !Ref LambdaFunction
  LambdaFunctionARN:
    Description: Lambda function ARN
    Value: !GetAtt LambdaFunction.Arn
    Export:
      Name: !Sub ${ResourcePrefix}AccountCollectorLambdaARN
Conditions:
  NeedDataBucketsKms: !Not [ !Equals [ !Ref DataBucketsKmsKeysArns, "" ] ]
Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ResourcePrefix}account-collector-LambdaRole"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - !Sub "lambda.${AWS::URLSuffix}"
        Version: 2012-10-17
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Path: /
      Policies:
        - PolicyName: "AssumeManagementRole"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:${AWS::Partition}:iam::*:role/${ManagementRoleName}" # Need to assume a Read role in all Management Accounts
        - PolicyName: "CloudWatch"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                  - "logs:DescribeLogStreams"
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/*"
        - PolicyName: "SSM"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "ssm:GetParameter"
                Resource: !Sub "arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:parameter/cid/${ResourcePrefix}*"
        - PolicyName: "Lambda"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "lambda:GetAccountSettings"
                Resource: "*"
        - PolicyName: "S3-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:GetObject"
                  - "s3:PutObject"
                Resource:
                  - !Sub "${DestinationBucketARN}/*"
        - !If
          - NeedDataBucketsKms
          - PolicyName: "KMS"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - "kms:GenerateDataKey"
                  Resource: !Split [ ',', !Ref DataBucketsKmsKeysArns ]
          - !Ref AWS::NoValue

    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: "Need explicit name to identify role actions"

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ResourcePrefix}account-collector-Lambda'
      Description: "Lambda function to retrieve the account list"
      Runtime: python3.12
      Architectures: [x86_64]
      Code:
          ZipFile: |
            import os
            import json
            import logging
            from functools import partial

            import boto3

            ROLE_NAME = os.environ.get('ROLE_NAME')
            RESOURCE_PREFIX = os.environ.get('RESOURCE_PREFIX')
            MANAGEMENT_ACCOUNT_IDS = os.environ.get('MANAGEMENT_ACCOUNT_IDS')
            BUCKET = os.environ.get('BUCKET_NAME')
            PREDEF_ACCOUNT_LIST_KEY = os.environ.get('PREDEF_ACCOUNT_LIST_KEY')
            LINKED_ACCOUNT_LIST_KEY = os.environ.get('LINKED_ACCOUNT_LIST_KEY')
            PAYER_ACCOUNT_LIST_KEY = os.environ.get('PAYER_ACCOUNT_LIST_KEY')
            EXCLUDED_ACCOUNT_LIST_KEY = os.environ.get('EXCLUDED_ACCOUNT_LIST_KEY')
            TMP_FILE = "/tmp/data.json"

            logger = logging.getLogger(__name__)
            logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))

            def lambda_handler(event, context): #pylint: disable=unused-argument
                logger.info(f"Incoming event: {event}")
                # need to confirm that the Lambda concurrency limit is sufficient to avoid throttling
                lambda_limit = boto3.client('lambda').get_account_settings()['AccountLimit']['ConcurrentExecutions']
                if lambda_limit < 500:
                    message = (f'Lambda concurrent executions limit of {lambda_limit} is not sufficient to run the Data Collection framework. '
                                'Please increase the limit to at least 500 (1000 is recommended). '
                                'See https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html.')
                    logger.error(message)
                    raise Exception(message) #pylint: disable=broad-exception-raised

                functions = { # keep keys same as boto3 services
                    'linked': iterate_linked_accounts,
                    'payers': partial(iterate_admins_accounts, None),
                    'organizations': partial(iterate_admins_accounts, 'organizations'),
                    'compute-optimizer': partial(iterate_admins_accounts, 'compute-optimizer'),
                    'backup': partial(iterate_admins_accounts, 'backup'),
                }
                account_type = event.get("Type", '').lower()
                if account_type not in functions:
                    raise Exception(f"Lambda event must have 'Type' parameter with value = ({list(functions.keys())})") #pylint: disable=broad-exception-raised

                account_iterator = functions[account_type]
                with open(TMP_FILE, "w", encoding='utf-8') as f:
                    count = 0
                    f.write("[\n")
                    for account in account_iterator():
                        if count > 0:
                            f.write(",\n")
                        f.write(json.dumps(account))
                        count += 1
                    f.write("\n]")

                if count == 0:
                    raise Exception('No accounts found. Check the log.') #pylint: disable=broad-exception-raised

                key = LINKED_ACCOUNT_LIST_KEY if account_type == 'linked' else PAYER_ACCOUNT_LIST_KEY
                s3 = boto3.client('s3')
                s3.upload_file(TMP_FILE, Bucket=BUCKET, Key=key)

                return {'statusCode': 200, 'accountList': key, 'bucket': BUCKET}

            def get_all_payers():
                for payer_id in MANAGEMENT_ACCOUNT_IDS.split(','):
                    yield payer_id.strip()

            def iterate_admins_accounts(service=None):
                ssm = boto3.client('ssm')
                for payer_id in get_all_payers():
                    account_id = payer_id # default
                    if service:
                        ssm_key = f'/cid/{RESOURCE_PREFIX}config/delegated-admin/{service}/{payer_id}'
                        try:
                            account_id = ssm.get_parameter(Name=ssm_key)['Parameter']['Value']
                        except ssm.exceptions.ParameterNotFound:
                            logger.warning(f'Not found ssm parameter {ssm_key}. Will use Management Account Id {payer_id}')
                    yield {"account": json.dumps({'account_id': account_id, 'account_name': '', 'payer_id': payer_id})}

            def iterate_linked_accounts():
                defined_accounts, ext = get_defined_list(BUCKET, PREDEF_ACCOUNT_LIST_KEY)
                try:
                    if defined_accounts:
                        logger.info(f'Using defined account list found in s3://{BUCKET}/{PREDEF_ACCOUNT_LIST_KEY}{ext} instead of payer organization')
                        for account_data in defined_accounts:
                            if ext == ".json":
                                account = json.loads(account_data)
                                yield format_account(account['account_id'], account['account_name'], account['payer_id'])
                            else:
                                account = account_data.split(',')
                                yield format_account(account[0].strip(), account[1].strip(), account[2].strip())
                    else:
                        logger.info('Using payer organization for the account list')
                        excluded_accounts = get_from_bucket(BUCKET, EXCLUDED_ACCOUNT_LIST_KEY)
                        if excluded_accounts:
                            logger.info(f'Found list of accounts to exclude in s3://{BUCKET}/{EXCLUDED_ACCOUNT_LIST_KEY}. Will only collect accounts that are not in the list')
                            excluded_accounts = [a.strip() for a in excluded_accounts[0].split(',') if a]
                        for org_account_data in iterate_admins_accounts('organizations'):
                            logger.info(f'Collecting accounts for payer {org_account_data}')
                            org_account = json.loads(org_account_data['account'])
                            logger.info(f'org_account: {org_account}')
                            organizations = get_client_with_role(service="organizations", account_id=org_account['account_id'], region="us-east-1") #MUST be us-east-1
                            for account in organizations.get_paginator("list_accounts").paginate().search("Accounts[?Status=='ACTIVE']"):
                                if excluded_accounts and account.get('Id') in excluded_accounts:
                                    logger.debug(f'Excluding account {account.get("Id")}')
                                    continue
                                yield format_account(account.get('Id'), account.get('Name'), org_account['payer_id'])
                except Exception as exc: #pylint: disable=broad-exception-caught
                    logger.error( f'{type(exc).__name__}: When trying to build linked account list. {exc} ')

            def get_defined_list(bucket, key):
                s3 = boto3.client("s3")
                exts = [".json", ".csv"]
                for ext in exts:
                    accts = get_from_bucket(bucket, key+ext, s3)
                    if accts:
                        return accts, ext
                logger.debug(f'Predefined account list not retrieved or not being used')
                return None, None

            def get_from_bucket(bucket, key, client=None):
                s3 = client if client else boto3.client("s3")
                try:
                    data = s3.get_object(Bucket=bucket, Key=key)
                    return data['Body'].read().decode('utf-8').strip('\n').split('\n')
                except Exception: #pylint: disable=broad-exception-caught
                    return None

            def format_account(account_id, account_name, payer_id):
                return {
                    "account": json.dumps({
                        'account_id': account_id,
                        'account_name': account_name,
                        'payer_id': payer_id,
                    })
                }


            def get_client_with_role(account_id, service, region):
                partition = boto3.session.Session().get_partition_for_region(region_name=region)
                credentials = boto3.client('sts').assume_role(
                    RoleArn=f"arn:{partition}:iam::{account_id}:role/{ROLE_NAME}",
                    RoleSessionName="data_collection"
                )['Credentials']
                return boto3.client(
                    service,
                    region_name=region,
                    aws_access_key_id=credentials['AccessKeyId'],
                    aws_secret_access_key=credentials['SecretAccessKey'],
                    aws_session_token=credentials['SessionToken'],
                )
      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 600
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          ROLE_NAME: !Ref ManagementRoleName
          MANAGEMENT_ACCOUNT_IDS: !Ref ManagementAccountID
          RESOURCE_PREFIX: !Ref ResourcePrefix
          BUCKET_NAME: !Ref DestinationBucket
          PREDEF_ACCOUNT_LIST_KEY: "account-list/account-list"
          LINKED_ACCOUNT_LIST_KEY: "account-list/linked-account-list.json"
          PAYER_ACCOUNT_LIST_KEY: "account-list/payer-account-list.json"
          EXCLUDED_ACCOUNT_LIST_KEY: "account-list/excluded-linked-account-list.csv"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: "No need for VPC in this case"
          - id: W92 #  Lambda functions should define ReservedConcurrentExecutions to reserve simultaneous executions
            reason: "No need for simultaneous execution"

  LogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/lambda/${LambdaFunction}"
      RetentionInDays: 60
