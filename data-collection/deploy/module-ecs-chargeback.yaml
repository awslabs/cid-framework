AWSTemplateFormatVersion: '2010-09-09'
Description: Collects ECS Cluster and service data and places into a bucket in the management account
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to be created to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  MultiAccountRoleName:
    Type: String
    Description: Name of the IAM role deployed in all accounts which can retrieve AWS Data.
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: ecs-chargeback
  GlueRoleARN:
    Type: String
    Description: Arn for the Glue Crawler role
  Schedule:
    Type: String
    Description: EventBridge Schedule to trigger the data collection
    Default: "rate(14 days)"
  ResourcePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  RegionsInScope:
    Type: String
    Description: "Comma Delimited list of AWS regions from which data about resources will be collected. Example: us-east-1,eu-west-1,ap-northeast-1"
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
  AccountCollectorLambdaARN:
    Type: String
    Description: Arn of the Account Collector Lambda
  CodeBucket:
    Type: String
    Description: Source code bucket
  StepFunctionTemplate:
    Type: String
    Description: S3 key to the JSON template for the StepFunction
  StepFunctionExecutionRoleARN:
    Type: String
    Description: Common role for Step Function execution
  SchedulerExecutionRoleARN:
    Type: String
    Description: Common role for module Scheduler execution
  CURTable:
    Type: String
    Description: The name of your Cost and Usage Report table in Athena
    Default: cid_cur.cur
  DataBucketsKmsKeysArns:
    Type: String
    Description: "ARNs of KMS Keys for data buckets and/or Glue Catalog. Comma separated list, no spaces. Keep empty if data Buckets and Glue Catalog are not Encrypted with KMS. You can also set it to '*' to grant decrypt permission for all the keys."
    Default: ""

Conditions:
  NeedDataBucketsKms: !Not [ !Equals [ !Ref DataBucketsKmsKeysArns, "" ] ]

Outputs:
  StepFunctionARN:
    Description: ARN for the module's Step Function
    Value: !GetAtt ModuleStepFunction.Arn

Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ResourcePrefix}${CFDataName}-LambdaRole"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - !Sub "lambda.${AWS::URLSuffix}"
        Version: 2012-10-17
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Path: /
      Policies:
        - PolicyName: "AssumeMultiAccountRole"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:${AWS::Partition}:iam::*:role/${MultiAccountRoleName}"
        - !If
          - NeedDataBucketsKms
          - PolicyName: "KMS"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - "kms:GenerateDataKey"
                  Resource: !Split [ ',', !Ref DataBucketsKmsKeysArns ]
          - !Ref AWS::NoValue
        - PolicyName: "S3Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource:
                  - !Sub "${DestinationBucketARN}/*"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: "Need explicit name to identify role actions"

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ResourcePrefix}${CFDataName}-Lambda'
      Description: !Sub "Lambda function to retrieve ${CFDataName}"
      Runtime: python3.12
      Architectures: [x86_64]
      Code:
        ZipFile: |
          #Module detail:
          # Name: ECS Chargeback
          # Account scope: Linked
          # Region(s): user-specified
          import os
          import json
          import uuid
          import logging
          from datetime import date, datetime

          import boto3
          from botocore.exceptions import ClientError
          from boto3.session import Session

          BUCKET = os.environ.get("BUCKET_NAME")
          PREFIX = os.environ.get("PREFIX")
          ROLE_NAME = os.environ.get('ROLE_NAME')
          TMP_FILE = "/tmp/data.json"
          START_TIME = str(datetime.now().isoformat())
          REGIONS = [r.strip() for r in os.environ.get("REGIONS","").split(',') if r]

          logger = logging.getLogger(__name__)
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))

          def lambda_handler(event, context):
              """ This lambda collects ECS Chargeback data and must be
              called from the corresponding Step Function to orchestrate
              """
              logger.info(f"Event data: {event}")
              sub_uuid = [context.aws_request_id, context.log_group_name, context.log_stream_name]
              run_uuid = event.get("run_uuid", str(uuid.uuid4()))
              total_services = 0

              try:
                  region = boto3.session.Session().region_name
                  account = json.loads(event.get("account","{}"))
                  payer_id = account.get("payer_id")
                  account_id = account.get("account_id")
                  if not (payer_id and account_id):
                      raise Exception(STATUS_NOT_ACCEPTABLE) #pylint: disable=broad-exception-raised

                  key = datetime.now().strftime(f"{PREFIX}/{PREFIX}-data/payer_id={payer_id}/year=%Y/month=%m/day=%d/{account_id}-%Y-%m-%d.json")
                  location=f"s3://{BUCKET}/{key}"
                  with open(TMP_FILE, "w") as f:
                      for region in REGIONS:
                          services_counter = 0
                          try:
                              session = assume_session(account_id, region)
                              client = session.client("ecs", region_name=region)
                              for page in client.get_paginator("list_clusters").paginate():
                                  for cluster in page["clusterArns"]:
                                      services_list = client.list_services(
                                          cluster=cluster.split("/")[1],
                                          maxResults=100
                                      )
                                      for i in services_list["serviceArns"]:
                                          services = client.describe_services(
                                              cluster=cluster.split("/")[1],
                                              services=[i.split("/")[2],],
                                              include=["TAGS"],
                                          )
                                          for service in services["services"]:
                                              data = {
                                                  "cluster": cluster.split("/")[1],
                                                  "services": service.get("serviceName"),
                                                  "servicesARN": i, #.split("/")[2]
                                                  "tags": service.get("tags"),
                                                  "account_id":account_id
                                              }
                                              jsondata = json.dumps(data)
                                              services_counter += 1
                                              f.write(jsondata + "\n")
                              total_services += services_counter
                              error = None
                          except Exception as exc: #pylint: disable=broad-exception-caught
                              error=exc
                          create_log_entry(payer_id, account_id, region=region, record_count=services_counter, location=location, error=error, run_uuid=run_uuid, sub_uuid=sub_uuid)

                  if total_services > 0:
                      client = boto3.client("s3")
                      client.upload_file(TMP_FILE, BUCKET, key)
                  return create_log_entry(payer_id, account_id, record_count=total_services, location=location, is_summary=True,
                                          run_uuid=run_uuid, sub_uuid=sub_uuid, record_context=f"service(s) for account {account_id} (all in scope regions)")

              except Exception as exc: #pylint: disable=broad-exception-caught
                  return create_log_entry(payer_id, account_id, region=region, record_count=total_services, error=exc, run_uuid=run_uuid, sub_uuid=sub_uuid)

          def assume_session(account_id, region):
              partition = boto3.session.Session().get_partition_for_region(region_name=region)
              cred = boto3.client('sts', region_name=region).assume_role(
                  RoleArn=f"arn:{partition}:iam::{account_id}:role/{ROLE_NAME}",
                  RoleSessionName="data_collection"
              )['Credentials']
              return boto3.Session(
                  aws_access_key_id=cred['AccessKeyId'],
                  aws_secret_access_key=cred['SecretAccessKey'],
                  aws_session_token=cred['SessionToken']
              )

          def list_ecs_regions():
              return boto3.Session().get_available_regions('ecs')

          def create_log_entry(payer_id="", account_id=None, start_time=None, status_code=None, region="", module=None, module_function="module-lambda", sub_code="",
                              params="", record_count=0, record_context="", description=None, location="", error=None, run_uuid="", sub_uuid=[], is_summary=False, store_it=True): # pylint: disable=too-many-locals
              """Format log entry for logging."""
              try:
                  # get the local account and region
                  dc_region = boto3.session.Session().region_name
                  dc_account_id = boto3.client('sts').get_caller_identity()['Account']
              except Exception as exc: #pylint: disable=broad-exception-caught
                  dc_region = ""
                  dc_account_id = ""
                  logger.error(f"{type(exc).__name__}: When trying to obtain local region and account information. Message: {str(exc)}")

              status_code, description = status_handler(error, record_count, is_summary, status_code, description, record_context)
              log_entry = {
                  "StartTime": start_time if start_time else START_TIME,
                  "EndTime":  str(datetime.now().isoformat()),
                  "DataCollectionRegion": dc_region,
                  "DataCollectionAccountId": dc_account_id,
                  "Module": module if module else PREFIX,
                  "ModuleFunction": module_function,
                  "Params": params,
                  "PayerId": payer_id,
                  "AccountId": account_id if account_id else payer_id,
                  "Region": region,
                  "StatusCode": status_code,
                  "SubCode": sub_code,
                  "RecordCount": record_count,
                  "Description": description,
                  "DataLocation": location if record_count > 0 else "",
                  "RunUUID": run_uuid,
                  "SubUUID": sub_uuid if isinstance(sub_uuid, list) else [sub_uuid],
                  "Service": "Lambda"
              }
              if status_code >= 400:
                  logger.error(description)
              if store_it:
                  store_log_entry(log_entry)
              logger.info(f"Result: {log_entry}")
              return {"statusCode": status_code, "logEntry": log_entry}

          def status_handler(error=None, record_count=0, is_summary=False, status_code=None, description="", record_context=""):
              """Codify status codes and descriptions for consistent logging."""
              if status_code:
                  return status_code, description
              if error:
                  exc_msg = str(error)
                  if exc_msg == str(STATUS_NOT_ACCEPTABLE):
                      return STATUS_NOT_ACCEPTABLE, ("InvocationError: Account parameters are not properly defined in request."
                          f"Please only trigger this Lambda from the corresponding StepFunction for this module.{' '+description if description else ''}")
                  if "AccessDenied" in exc_msg:
                      return STATUS_NOT_AUTHORIZED, f"AccessDenied: Unable to assume role {ROLE_NAME}. Please make sure the role exists. {exc_msg}"
                  if 'The security token included in the request is invalid' in exc_msg:
                      return STATUS_FORBIDDEN, f'{type(error).__name__}: Region might not be activated.'
                  return STATUS_SERVER_ERROR, f"{type(error).__name__}: with message {exc_msg}"
              # For all others, assume success
              description = f"Lambda execution successful: {record_count} {(record_context+' ') if record_context else ''}record{'s' if (record_count > 1 or record_count == 0) else ''} found.{' '+description if description else ''}"
              if is_summary:
                  return STATUS_MULTI_STATUS, "Multi-part "+description
              if record_count == 0:
                  return STATUS_OKAY_NO_CONTENT, description
              return STATUS_OKAY, description

          def store_log_entry(log_entry):
              """Store the log entry to S3."""
              key = datetime.now().strftime(f"logs/%Y/%m/%d/{PREFIX}-{uuid.uuid4()}.json")
              try:
                  boto3.client('s3').put_object(Body=json.dumps(log_entry), Bucket=BUCKET, Key=key)
              except Exception as exc: #pylint: disable=broad-exception-caught
                  logger.error(f"Error storing log entry to S3: {exc}")

          STATUS_OKAY = 200
          STATUS_OKAY_NO_CONTENT = 204
          STATUS_MULTI_STATUS = 207
          STATUS_NOT_AUTHORIZED = 401
          STATUS_FORBIDDEN = 403
          STATUS_NOT_FOUND = 404
          STATUS_NOT_ACCEPTABLE = 406
          STATUS_CONFLICT = 409
          STATUS_TOO_MANY_REQUESTS = 429
          STATUS_SERVER_ERROR = 500
          STATUS_NOT_IMPLEMENTED = 501
      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 300
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          PREFIX: !Ref CFDataName
          ROLE_NAME: !Ref MultiAccountRoleName
          REGIONS: !Ref RegionsInScope
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: "No need for VPC in this case"
          - id: W92 #  Lambda functions should define ReservedConcurrentExecutions to reserve simultaneous executions
            reason: "No need for simultaneous execution"

  LogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/lambda/${LambdaFunction}"
      RetentionInDays: 60

  Crawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"

  ModuleStepFunction:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub '${ResourcePrefix}${CFDataName}-StateMachine'
      StateMachineType: STANDARD
      RoleArn: !Ref StepFunctionExecutionRoleARN
      DefinitionS3Location:
        Bucket: !Ref CodeBucket
        Key: !Ref StepFunctionTemplate
      DefinitionSubstitutions:
        AccountCollectorLambdaARN: !Ref AccountCollectorLambdaARN
        ModuleLambdaARN: !GetAtt LambdaFunction.Arn
        Crawlers: !Sub '["${ResourcePrefix}${CFDataName}-Crawler"]'
        CollectionType: "LINKED"
        Params: ''
        Module: !Ref CFDataName
        DeployRegion: !Ref AWS::Region
        Account: !Ref AWS::AccountId
        Prefix: !Ref ResourcePrefix
        Bucket: !Ref DestinationBucket

  ModuleRefreshSchedule:
    Type: 'AWS::Scheduler::Schedule'
    Properties:
      Description: !Sub 'Scheduler for the ODC ${CFDataName} module'
      Name: !Sub '${ResourcePrefix}${CFDataName}-RefreshSchedule'
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      FlexibleTimeWindow:
        MaximumWindowInMinutes: 30
        Mode: 'FLEXIBLE'
      Target:
        Arn: !GetAtt ModuleStepFunction.Arn
        RoleArn: !Ref SchedulerExecutionRoleARN
        Input: !Sub '{"module_lambda":"${LambdaFunction.Arn}","crawlers": ["${ResourcePrefix}${CFDataName}-Crawler"]}'

  AnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName

  AthenaClusterMetadataView:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: ecs_chargeback_cluster_metadata_view
      QueryString: |
          CREATE OR REPLACE VIEW ecs_chargeback_cluster_metadata_view AS
          SELECT
            *
          , "tag"."value"
          FROM
            ( ecs_chargeback_ecs_services_clusters_data
              CROSS JOIN UNNEST(cast(json_parse("tags") as array<varchar>)) t(tag)
            )
          WHERE ("tag"."key" = 'BU')

  AthenaEc2ClusterCostsView:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: ecs_chargeback_ec2_cluster_costs
      QueryString: !Sub |
        CREATE OR REPLACE VIEW ecs_chargeback_ec2_cluster_costs AS
        SELECT
          line_item_product_code
        , line_item_usage_account_id
        , line_item_resource_id
        , line_item_usage_type
        , sum((CASE WHEN (line_item_line_item_type = 'SavingsPlanCoveredUsage') THEN line_item_usage_amount WHEN (line_item_line_item_type = 'DiscountedUsage') THEN line_item_usage_amount WHEN (line_item_line_item_type = 'Usage') THEN line_item_usage_amount ELSE 0 END)) sum_line_item_usage_amount
        , sum(line_item_unblended_cost) unblended_cost
        , sum((CASE WHEN (line_item_line_item_type = 'SavingsPlanCoveredUsage') THEN savings_plan_savings_plan_effective_cost WHEN (line_item_line_item_type = 'SavingsPlanRecurringFee') THEN (savings_plan_total_commitment_to_date - savings_plan_used_commitment) WHEN (line_item_line_item_type = 'SavingsPlanNegation') THEN 0 WHEN (line_item_line_item_type = 'SavingsPlanUpfrontFee') THEN 0 WHEN (line_item_line_item_type = 'DiscountedUsage') THEN reservation_effective_cost WHEN (line_item_line_item_type = 'RIFee') THEN (reservation_unused_amortized_upfront_fee_for_billing_period + reservation_unused_recurring_fee) ELSE line_item_unblended_cost END)) sum_line_item_amortized_cost
        , month
        , year
        FROM
          ${CURTable}
        WHERE (((product_product_name = 'Amazon Elastic Compute Cloud') AND ((resource_tags_user_name LIKE '%ECS%') OR (resource_tags_user_name LIKE '%ecs%'))) AND (((line_item_usage_type LIKE '%BoxUsage%') OR (line_item_usage_type LIKE '%Spot%')) OR (line_item_usage_type LIKE '%%EBS%%Volume%%')))
        GROUP BY resource_tags_user_name, line_item_product_code, line_item_usage_account_id, line_item_resource_id, line_item_usage_type, month, year

  AthenaBUUsageView:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: ecs_chargeback_bu_usage
      QueryString: !Sub |
        CREATE OR REPLACE VIEW ecs_chargeback_bu_usage AS
        SELECT
          "bill_payer_account_id"
        , "line_item_product_code"
        , "line_item_usage_account_id"
        , "line_item_resource_id"
        , "task"
        , "resource_tags_aws_ecs_service_Name"
        , "line_item_usage_type"
        , "line_item_operation"
        , "sum"(CAST("sum_line_item_usage_amount" AS double)) "sum_line_item_usage_amount"
        , "cur"."month"
        , "cur"."year"
        , "cluster"
        , "services"
        , "servicearn"
        , "account_id"
        , "value"
        FROM
          ((
          SELECT
            "bill_payer_account_id"
          , "line_item_product_code"
          , "line_item_usage_account_id"
          , "line_item_resource_id"
          , "split"("line_item_resource_id", '/')[2] "task"
          , "resource_tags_aws_ecs_service_Name"
          , "line_item_usage_type"
          , "line_item_operation"
          , "sum"(CAST("line_item_usage_amount" AS double)) "sum_line_item_usage_amount"
          , "month"
          , "year"
          FROM
            ${CURTable}
          WHERE ((("line_item_operation" = 'ECSTask-EC2') AND ("line_item_product_code" IN ('AmazonECS'))) AND ("line_item_usage_type" LIKE '%GB%'))
          GROUP BY "bill_payer_account_id", "line_item_usage_account_id", "line_item_product_code", "line_item_operation", "line_item_resource_id", "resource_tags_aws_ecs_service_Name", "line_item_usage_type", "line_item_operation", "month", "year"
        )  cur
        LEFT JOIN (
          SELECT
            "cluster"
          , "services"
          , "servicearn"
          , "value"
          , "year"
          , "month"
          , "account_id"
          FROM
            ecs_chargeback_cluster_metadata_view
        )  clusters_data ON ((("clusters_data"."account_id" = "cur"."line_item_usage_account_id") AND (("clusters_data"."services" = "cur"."resource_tags_aws_ecs_service_name") AND ("clusters_data"."year" = "cur"."year"))) AND ("clusters_data"."month" = "cur"."month")))
        GROUP BY "bill_payer_account_id", "line_item_usage_account_id", "line_item_product_code", "line_item_operation", "line_item_resource_id", "resource_tags_aws_ecs_service_Name", "line_item_usage_type", "line_item_operation", "cur"."month", "cur"."year", "cluster", "services", "servicearn", "value", "task", "account_id"

  AthenaEC2CChargeBackQuery:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: ecs_chargeback_report
      QueryString: |
        SELECT ecs_chargeback_bu_usage.line_item_usage_account_id, sum(sum_line_item_usage_amount) AS task_usage, total_usage, (sum(sum_line_item_usage_amount)/total_usage) as percent,  ec2_cost, ((sum(sum_line_item_usage_amount)/total_usage)*ec2_cost) as ecs_cost,
          "cluster",
          services,
          servicearn,
          value,
          ecs_chargeback_bu_usage.month,
          ecs_chargeback_bu_usage.year
        FROM "ecs_chargeback_bu_usage"
        LEFT JOIN (select line_item_usage_account_id, sum(sum_line_item_usage_amount) as total_usage, year, month from "ecs_chargeback_bu_usage" where "cluster" <> '' group by line_item_usage_account_id, year, month) sum
        on sum.line_item_usage_account_id = ecs_chargeback_bu_usage.line_item_usage_account_id
        and sum.month=ecs_chargeback_bu_usage.month
        and sum.year=ecs_chargeback_bu_usage.year
        LEFT JOIN
        (SELECT line_item_usage_account_id, month, year, sum(sum_line_item_amortized_cost) as ec2_cost FROM "ec2_cluster_costs_view" group by  line_item_usage_account_id,month,year) ec2_cost
        on ec2_cost.month=ecs_chargeback_bu_usage.month
        and ec2_cost.year=ecs_chargeback_bu_usage.year
        and ec2_cost.line_item_usage_account_id=ecs_chargeback_bu_usage.line_item_usage_account_id
        WHERE "cluster" <> ''  and  if((date_format(current_timestamp , '%M') = 'January'),ecs_chargeback_bu_usage.month = '12', ecs_chargeback_bu_usage.month = CAST((month(now())-1) AS VARCHAR) )
        and  if((date_format(current_timestamp , '%M') = 'January'), ecs_chargeback_bu_usage.year = CAST((year(now())-1) AS VARCHAR) ,ecs_chargeback_bu_usage.year = CAST(year(now()) AS VARCHAR))
        GROUP BY  "cluster", services, servicearn, value, ecs_chargeback_bu_usage.month, ecs_chargeback_bu_usage.year, ecs_chargeback_bu_usage.line_item_usage_account_id, total_usage, ec2_cost
