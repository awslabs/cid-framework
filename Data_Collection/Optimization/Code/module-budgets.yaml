AWSTemplateFormatVersion: '2010-09-09'
Description: Retrieves Budgets data
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to be created to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  MultiAccountRoleName:
    Type: String
    Description: Name of the IAM role deployed in all accounts which can retrieve AWS Data.
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: budgets
  GlueRoleARN:
    Type: String
    Description: Arn for the Glue Crawler role
  Schedule:
    Type: String
    Description: EventBridge Schedule to trigger the data collection
    Default: "rate(14 days)"
  RolePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
  AccountIteratorStepFunctionARN:
    Type: String
    Description: Arn of the universal Account Iterator Step Function

Outputs:
  AthenaSavedQuery:
    Description: This saved query will provide you a summary of your lambda data
    Value:
      Ref: AthenaQuery
  LambdaRoleARN:
    Description: Role for Lambda execution of collection data.
    Value: !GetAtt LambdaRole.Arn
  LambdaFunctionARN:
    Description: ARN for the module's primary Lambda function
    Value: !GetAtt LambdaFunction.Arn

Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${RolePrefix}Lambda-Role-${CFDataName}"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: !Sub "Assume-Management-${CFDataName}-Account-Role"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:aws:iam::*:role/${MultiAccountRoleName}" # Need to assume a Read role in all Accounts
        - PolicyName: !Sub "${CFDataName}-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:ListBucket"
                  - "s3:GetBucketLocation"
                Resource:
                  - !Ref DestinationBucketARN
                  - !Sub "${DestinationBucketARN}/*"
              - Effect: "Allow"
                Action:
                  - "budgets:ViewBudget"
                  - "budgets:Describe*"
                Resource: !Sub "arn:aws:budgets:${AWS::Region}:${AWS::AccountId}:*"
  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${RolePrefix}${CFDataName}-Lambda'
      Description: !Sub "LambdaFunction to retrieve ${CFDataName}"
      Runtime: python3.8
      Code:
        ZipFile: |
          #Author Stephanie Gooch 2021
          import os
          import json
          import logging
          import datetime
          from json import JSONEncoder

          import boto3

          BUCKET = os.environ["BUCKET_NAME"]
          PREFIX = os.environ["PREFIX"]
          ROLE_NAME = os.environ['ROLENAME']
          TMP_FILE = "/tmp/data.json"

          logger = logging.getLogger()
          if "LOG_LEVEL" in os.environ:
              numeric_level = getattr(logging, os.environ['LOG_LEVEL'].upper(), None)
              if not isinstance(numeric_level, int):
                  raise ValueError('Invalid log level: %s' % numeric_level)
              logger.setLevel(level=numeric_level)
          else:
              logger.setLevel(logging.INFO)

          # subclass JSONEncoder
          class DateTimeEncoder(JSONEncoder):
              # Override the default method
              def default(self, obj):
                  if isinstance(obj, (datetime.date, datetime.datetime)):
                      return obj.isoformat()

          def assume_role(account_id, service):
              cred = boto3.client('sts').assume_role(
                  RoleArn=f"arn:aws:iam::{account_id}:role/{ROLE_NAME}",
                  RoleSessionName="data_collection"
              )['Credentials']
              return boto3.client(
                  service,
                  aws_access_key_id=cred['AccessKeyId'],
                  aws_secret_access_key=cred['SecretAccessKey'],
                  aws_session_token=cred['SessionToken']
              )

          def lambda_handler(event, context):
              print(json.dumps(event))
              if 'account' not in event:
                  raise ValueError(
                      "Please do not trigger this Lambda manually."
                      "Find the corresponding state machine in Step Functions and Trigger from there."
                  )
              collection_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
              try:
                  account = json.loads(event["account"][0])
                  account_id = account["account_id"]
                  account_name = account["account_name"]
                  payer_id = account["payer_id"]
                  logger.info(f"Collecting data for account: {account_id}")
                  budgets_client = assume_role(account_id, "budgets")
                  paginator = budgets_client.get_paginator("describe_budgets") #Paginator for a large list of accounts
                  response_iterator = paginator.paginate(AccountId=account_id)
                  count = 0
                  with open(TMP_FILE, "w") as f:
                      for budgets in response_iterator:
                          if not 'Budgets' in budgets: continue
                          for budget in budgets['Budgets']:
                              count += 1
                              budget['collection_time'] = collection_time
                              logger.debug(budget)
                              budget.update({'Account_ID': account_id, 'Account_Name': account_name})
                              if 'CostFilters' not in budget or len(budget['CostFilters']) == 0 or 'PlannedBudgetLimits' not in budget:
                                  budget.update({'CostFilters': {'Filter': ['None']}})
                              dataJSONData = json.dumps(budget, cls=DateTimeEncoder)
                              f.write(dataJSONData)
                              f.write("\n")
                  logger.info(f"Budgets collected: {count}")
                  s3_upload(account_id, payer_id)
              except Exception as e:
                  logger.warning(f"Error: {type(e)} {e}")

          def s3_upload(account_id, payer_id):
              if os.path.getsize(TMP_FILE) == 0:
                  logger.info(f"No data in file for {PREFIX}")
                  return
              key = datetime.datetime.now().strftime(f"{PREFIX}/{PREFIX}-data/payer_id={payer_id}/year=%Y/month=%m/budgets-{account_id}.json")
              try:
                  res = boto3.client('s3').upload_file(TMP_FILE, BUCKET, key)
                  logger.info(f'res={res}')
                  logger.info(f"Budget data for {account_id} stored at s3://{BUCKET}/{key}")
              except Exception as exc:
                  logger.warning(exc)
      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 300
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          PREFIX: !Ref CFDataName
          ROLENAME: !Ref MultiAccountRoleName

  AthenaQuery:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: !Sub "Provides a summary view of the ${CFDataName}"
      Name: !Sub "${CFDataName}_view"
      QueryString:
        CREATE OR REPLACE VIEW budgets_view AS
        SELECT
          budgetname budget_name
        , CAST(budgetlimit.amount AS decimal) budget_amount
        , CAST(calculatedspend.actualspend.amount AS decimal) actualspend
        , CAST(calculatedspend.forecastedspend.amount AS decimal) forecastedspend
        , timeunit
        , budgettype budget_type
        , account_id
        , timeperiod.start start_date
        , timeperiod."end"  end_date
        , year budget_year
        , month budget_month
        FROM
          optimization_data.budgets_data
        WHERE (budgettype = 'COST')  AND costfilters.filter[1] = 'None'

  Crawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${RolePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"

  ScheduleExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      RoleName: !Sub "${RolePrefix}EventBridge-Scheduler-Role-${CFDataName}"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - scheduler.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: "ExecuteStateMachinePolicy"
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - states:StartExecution
                Resource:
                  - !Ref AccountIteratorStepFunctionARN

  ModuleRefreshSchedule:
    Type: 'AWS::Scheduler::Schedule'
    Properties:
      Description: !Sub 'Scheduler for the ODC ${CFDataName} module'
      Name: !Sub '${CFDataName}-RefreshSchedule'
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      FlexibleTimeWindow: 
        Mode: 'OFF'
      Target:
          Arn: !Ref AccountIteratorStepFunctionARN
          RoleArn: !GetAtt ScheduleExecutionRole.Arn
          Input: !Sub '{"module_lambda":"${LambdaFunction.Arn}","crawlers": ["${RolePrefix}${CFDataName}-Crawler"]}'

  LambdaAnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName